{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Adapted from salesforce@LAVIS and Vision-CAIR@MiniGPT-4. Below is the original copyright:\n",
    " Copyright (c) 2022, salesforce.com, inc.\n",
    " All rights reserved.\n",
    " SPDX-License-Identifier: BSD-3-Clause\n",
    " For full license text, see the LICENSE_Lavis file in the repo root or https://opensource.org/licenses/BSD-3-Clause\n",
    "\"\"\"\n",
    "\n",
    "import argparse\n",
    "import os\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.backends.cudnn as cudnn\n",
    "\n",
    "import video_llama.tasks as tasks\n",
    "from video_llama.common.config import Config\n",
    "from video_llama.common.dist_utils import get_rank, init_distributed_mode\n",
    "from video_llama.common.logger import setup_logger\n",
    "from video_llama.common.optims import (\n",
    "    LinearWarmupCosineLRScheduler,\n",
    "    LinearWarmupStepLRScheduler,\n",
    ")\n",
    "from video_llama.common.registry import registry\n",
    "from video_llama.common.utils import now\n",
    "\n",
    "# imports modules for registration\n",
    "from video_llama.datasets.builders import *\n",
    "from video_llama.models import *\n",
    "from video_llama.processors import *\n",
    "from video_llama.runners import *\n",
    "from video_llama.tasks import *\n",
    "\n",
    "import yaml ## ADD\n",
    "\n",
    "\n",
    "def parse_args():\n",
    "    parser = argparse.ArgumentParser(description=\"Training\")\n",
    "\n",
    "    parser.add_argument(\"--cfg-path\", required=True, help=\"path to configuration file.\")\n",
    "    parser.add_argument(\n",
    "        \"--options\",\n",
    "        nargs=\"+\",\n",
    "        help=\"override some settings in the used config, the key-value pair \"\n",
    "        \"in xxx=yyy format will be merged into config file (deprecate), \"\n",
    "        \"change to --cfg-options instead.\",\n",
    "    )\n",
    "\n",
    "    args = parser.parse_args()\n",
    "    # if 'LOCAL_RANK' not in os.environ:\n",
    "    #     os.environ['LOCAL_RANK'] = str(args.local_rank)\n",
    "\n",
    "    return args\n",
    "\n",
    "\n",
    "def setup_seeds(config):\n",
    "    seed = config.run_cfg.seed + get_rank()\n",
    "\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "\n",
    "    cudnn.benchmark = False\n",
    "    cudnn.deterministic = True\n",
    "\n",
    "\n",
    "def get_runner_class(cfg):\n",
    "    \"\"\"\n",
    "    Get runner class from config. Default to epoch-based runner.\n",
    "    \"\"\"\n",
    "    runner_cls = registry.get_runner_class(cfg.run_cfg.get(\"runner\", \"runner_base\"))\n",
    "\n",
    "    return runner_cls\n",
    "\n",
    "\n",
    "def setup_runner(cfg):\n",
    "    # set before init_distributed_mode() to ensure the same job_id shared across all ranks.\n",
    "    job_id = now()\n",
    "\n",
    "    init_distributed_mode(cfg.run_cfg)\n",
    "\n",
    "    # setup_seeds(cfg.run_cfg.seed + get_rank())\n",
    "\n",
    "    # set after init_distributed_mode() to only log on master.\n",
    "    setup_logger()\n",
    "\n",
    "    cfg.pretty_print()\n",
    "\n",
    "    task = tasks.setup_task(cfg)\n",
    "    datasets = task.build_datasets(cfg)\n",
    "\n",
    "    runner_cls = get_runner_class(cfg)\n",
    "    runner = runner_cls(\n",
    "        cfg=cfg, job_id=job_id, task=task, model=None, datasets=datasets\n",
    "    )\n",
    "\n",
    "    return runner\n",
    "\n",
    "args = argparse.Namespace()\n",
    "\n",
    "# Set attributes manually\n",
    "args.cfg_path = \"./train_configs/drive_finetune.yaml\"\n",
    "args.options = []\n",
    "\n",
    "cfg = Config(args)\n",
    "\n",
    "# # Update the configuration with the loaded dictionary\n",
    "# for key, value in cfg_dict.items():\n",
    "#     setattr(cfg, key, value)\n",
    "# # Setup the runner\n",
    "# setup_seeds(cfg.run_cfg.seed + get_rank())\n",
    "\n",
    "job_id = now()\n",
    "\n",
    "init_distributed_mode(cfg.run_cfg)\n",
    "\n",
    "# setup_seeds(cfg.run_cfg.seed + get_rank())\n",
    "\n",
    "# set after init_distributed_mode() to only log on master.\n",
    "setup_logger()\n",
    "\n",
    "cfg.pretty_print()\n",
    "\n",
    "task = tasks.setup_task(cfg)\n",
    "datasets = task.build_datasets(cfg)\n",
    "\n",
    "runner_cls = get_runner_class(cfg)\n",
    "runner = runner_cls(\n",
    "    cfg=cfg, job_id=job_id, task=task, model=None, datasets=datasets\n",
    ")\n",
    "\n",
    "# Train using the runner\n",
    "# runner.train()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': <video_llama.datasets.datasets.bdd_instruct_dataset.BDD_Instruct_Dataset at 0x29d0dd600>}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets['bdd_instruct']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'video_path' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[0;32m~/Library/CloudStorage/GoogleDrive-sy.park574@gmail.com/내 드라이브/Video-LLaMA-2/video_llama/datasets/datasets/bdd_instruct_dataset.py:88\u001b[0m, in \u001b[0;36mBDD_Instruct_Dataset.__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 88\u001b[0m     sample \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mannotation[index]\n\u001b[1;32m     90\u001b[0m     video_path \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_video_path(sample)\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mfor\u001b[39;00m index, data \u001b[39min\u001b[39;00m datasets[\u001b[39m'\u001b[39m\u001b[39mbdd_instruct\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m'\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m'\u001b[39m]:\n\u001b[1;32m      2\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mSample \u001b[39m\u001b[39m{\u001b[39;00mindex\u001b[39m \u001b[39m\u001b[39m+\u001b[39m\u001b[39m \u001b[39m\u001b[39m1\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m:\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      3\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mKeys in sample: \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlist\u001b[39m(data\u001b[39m.\u001b[39mkeys())\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Library/CloudStorage/GoogleDrive-sy.park574@gmail.com/내 드라이브/Video-LLaMA-2/video_llama/datasets/datasets/bdd_instruct_dataset.py:133\u001b[0m, in \u001b[0;36mBDD_Instruct_Dataset.__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    130\u001b[0m     data_dict[\u001b[39m\"\u001b[39m\u001b[39mimage\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m video\n\u001b[1;32m    131\u001b[0m \u001b[39mexcept\u001b[39;00m:\n\u001b[1;32m    132\u001b[0m     \u001b[39mprint\u001b[39m(\n\u001b[0;32m--> 133\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mFailed to load examples with video: \u001b[39m\u001b[39m{\u001b[39;00mvideo_path\u001b[39m}\u001b[39;00m\u001b[39m. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    134\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mWill randomly sample an example as a replacement.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    135\u001b[0m     )\n\u001b[1;32m    136\u001b[0m     index \u001b[39m=\u001b[39m random\u001b[39m.\u001b[39mrandint(\u001b[39m0\u001b[39m, \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m)\n\u001b[1;32m    137\u001b[0m     \u001b[39mcontinue\u001b[39;00m\n",
      "\u001b[0;31mUnboundLocalError\u001b[0m: local variable 'video_path' referenced before assignment"
     ]
    }
   ],
   "source": [
    "for index, data in datasets['webvid_instruct']['train']:\n",
    "    print(f\"Sample {index + 1}:\")\n",
    "    print(f\"Keys in sample: {list(data.keys())}\")\n",
    "    # Print out specific data from the sample\n",
    "    print(f\"Video path: {data['video_path']}\")\n",
    "    print(f\"Target label: {data['target_label']}\")\n",
    "    # Add more data fields as needed\n",
    "    print(\"-\" * 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
